# main_complete.py
"""
í™”ì ë¶„ë¦¬ ìŒì„± ì¸ì‹ í†µí•© ì‹œìŠ¤í…œ (ì™„ì „ ë²„ì „)
"""

import argparse
import os
import sys
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd
import json
from datetime import datetime
import traceback

# ë¡œì»¬ ëª¨ë“ˆ import
from config import (
    model_config, audio_config, processing_config, system_config,
    update_config_for_gpu
)
from audio_utils import AudioProcessor, VADProcessor
from speaker_diarization import create_speaker_diarizer, post_process_speaker_labels
from speech_recognition import create_asr_model, ASRPostProcessor
from system_monitor import ResourceMonitor, print_system_info, PerformanceAnalyzer


class SpeakerDiarizationSystem:
    """í†µí•© í™”ì ë¶„ë¦¬ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ"""

    def __init__(self, config_override: Dict = None):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""

        print("ğŸš€ í™”ì ë¶„ë¦¬ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")

        # GPU ìµœì í™” ì„¤ì • ì ìš©
        update_config_for_gpu()

        # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ì ìš©
        if config_override:
            self._apply_config_override(config_override)

        # ëª¨ë“ˆ ì´ˆê¸°í™”
        self.audio_processor = AudioProcessor()
        self.vad_processor = VADProcessor()
        self.asr_post_processor = ASRPostProcessor()

        # ëª¨ë¸ë“¤ (ì§€ì—° ë¡œë”©)
        self.speaker_diarizer = None
        self.asr_model = None

        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def _apply_config_override(self, override: Dict):
        """ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ì ìš©"""

        if 'whisper_model' in override:
            model_config.whisper_model_name = override['whisper_model']

        if 'batch_size' in override:
            processing_config.batch_size = override['batch_size']

        if 'chunk_duration' in override:
            processing_config.chunk_duration = override['chunk_duration']

    def load_models(self, force_reload: bool = False):
        """ëª¨ë¸ ë¡œë“œ"""

        if self.speaker_diarizer is None or force_reload:
            print("ğŸ“¡ í™”ì ë¶„ë¦¬ ëª¨ë¸ ë¡œë”©...")
            with ResourceMonitor("speaker_diarizer_loading"):
                self.speaker_diarizer = create_speaker_diarizer("auto")

        if self.asr_model is None or force_reload:
            print("ğŸ¤ ìŒì„± ì¸ì‹ ëª¨ë¸ ë¡œë”©...")
            with ResourceMonitor("asr_model_loading"):
                self.asr_model = create_asr_model("auto")

    def process_audio_file(self, audio_path: str,
                           output_dir: str = None,
                           n_speakers: int = None) -> Dict:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²´ ì²˜ë¦¬"""

        print(f"ğŸ“ ì²˜ë¦¬ ì‹œì‘: {audio_path}")

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        if output_dir is None:
            output_dir = Path(audio_path).parent / "output"

        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)

        try:
            # ëª¨ë¸ ë¡œë“œ
            self.load_models()

            with ResourceMonitor("full_audio_processing") as monitor:

                # 1. ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬
                print("ğŸ”Š ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬")
                audio, sr = self.audio_processor.load_audio(audio_path)

                # ì˜¤ë””ì˜¤ í’ˆì§ˆ ì²´í¬
                quality = self.audio_processor.check_audio_quality(audio, sr)
                print(f"ì˜¤ë””ì˜¤ í’ˆì§ˆ: {'âœ… ì–‘í˜¸' if quality['overall_ok'] else 'âš ï¸ ì£¼ì˜'}")

                # ì˜¤ë””ì˜¤ ì •ê·œí™”
                audio = self.audio_processor.normalize_audio(audio)

                # 2. ìŒì„± í™œë™ ê°ì§€ (VAD)
                print("ğŸ¯ ìŒì„± í™œë™ ê°ì§€")
                segments = self.vad_processor.enhanced_vad(audio, sr)
                segments = self.vad_processor.merge_close_segments(segments)

                print(f"ê°ì§€ëœ ìŒì„± êµ¬ê°„: {len(segments)}ê°œ")

                if not segments:
                    return {
                        'success': False,
                        'error': 'ìŒì„± êµ¬ê°„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                        'audio_quality': quality
                    }

                # 3. í™”ì ë¶„ë¦¬
                print("ğŸ‘¥ í™”ì ë¶„ë¦¬")
                speaker_labels = self.speaker_diarizer.diarize(audio, sr, segments)

                # í›„ì²˜ë¦¬
                speaker_labels = post_process_speaker_labels(speaker_labels, segments)

                unique_speakers = len(set(speaker_labels))
                print(f"ì‹ë³„ëœ í™”ì ìˆ˜: {unique_speakers}ëª…")

                # 4. ìŒì„± ì¸ì‹
                print("ğŸ—£ï¸ ìŒì„± ì¸ì‹")
                transcription_results = self.asr_model.transcribe_segments(audio, segments, sr)

                # 5. ê²°ê³¼ í†µí•©
                print("ğŸ”„ ê²°ê³¼ í†µí•© ë° í›„ì²˜ë¦¬")
                final_results = self._integrate_results(
                    transcription_results, speaker_labels, segments, quality
                )

                # 6. ê²°ê³¼ ì €ì¥
                print("ğŸ’¾ ê²°ê³¼ ì €ì¥")
                output_files = self._save_results(final_results, output_dir, audio_path)

                # ì²˜ë¦¬ ì™„ë£Œ
                processing_info = monitor.get_resource_usage()

                # ì•ˆì „í•œ í†µê³„ ê³„ì‚°
                total_duration = len(audio) / sr if audio is not None and sr > 0 else 0

                return {
                    'success': True,
                    'num_segments': len(final_results),
                    'num_speakers': unique_speakers,
                    'audio_duration': total_duration,
                    'output_files': output_files,
                    'audio_quality': quality,
                    'processing_info': processing_info
                }

        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                'success': False,
                'error': str(e),
                'audio_quality': quality if 'quality' in locals() else {}
            }

    def process_batch(self, audio_files: List[str],
                      output_dir: str = None) -> List[Dict]:
        """ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬"""

        print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(audio_files)}ê°œ íŒŒì¼")

        if output_dir is None:
            output_dir = Path("./batch_output")

        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True)

        # ëª¨ë¸ í•œ ë²ˆë§Œ ë¡œë“œ
        try:
            self.load_models()
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return [{
                'success': False,
                'error': f'ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}',
                'file_path': 'ALL'
            }]

        results = []

        for i, audio_file in enumerate(audio_files):
            print(f"\n[{i + 1}/{len(audio_files)}] {audio_file}")

            try:
                # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                if not os.path.exists(audio_file):
                    print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {audio_file}")
                    results.append({
                        'success': False,
                        'file_path': audio_file,
                        'error': 'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ'
                    })
                    continue

                # ê°œë³„ íŒŒì¼ ì²˜ë¦¬
                file_output_dir = output_dir / Path(audio_file).stem
                result = self.process_audio_file(audio_file, file_output_dir)
                result['file_path'] = audio_file
                results.append(result)

            except Exception as e:
                print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                results.append({
                    'success': False,
                    'file_path': audio_file,
                    'error': str(e)
                })

                # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì˜¤ë¥˜ í›„)
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                except:
                    pass

        # ë°°ì¹˜ ê²°ê³¼ ìš”ì•½ ì €ì¥
        try:
            self._save_batch_summary(results, output_dir)
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ìš”ì•½ ì €ì¥ ì‹¤íŒ¨: {e}")

        return results

    def _integrate_results(self, transcriptions: List[Dict],
                           speaker_labels: List[int],
                           segments: List[tuple],
                           audio_quality: Dict) -> List[Dict]:
        """ê²°ê³¼ í†µí•© ë° í›„ì²˜ë¦¬"""

        integrated_results = []

        # ì „ì‚¬ ê²°ê³¼ì™€ í™”ì ë¼ë²¨ ë§¤ì¹­
        for i, transcription in enumerate(transcriptions):
            segment_id = transcription.get('segment_id', i)

            # ì•ˆì „í•œ ì¸ë±ìŠ¤ ì ‘ê·¼
            if segment_id < len(speaker_labels) and segment_id < len(segments):
                speaker_label = speaker_labels[segment_id]

                # í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
                cleaned_text = self.asr_post_processor.clean_transcription(
                    transcription['text']
                )

                if cleaned_text:  # ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ

                    # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
                    confidence = self.asr_post_processor.calculate_confidence_score(
                        cleaned_text, audio_quality
                    )

                    integrated_results.append({
                        'segment_id': segment_id,
                        'speaker_id': f"í™”ì_{speaker_label}",
                        'start_time': transcription.get('start_time', 0),
                        'end_time': transcription.get('end_time', 0),
                        'duration': transcription.get('duration', 0),
                        'text': cleaned_text,
                        'original_text': transcription['text'],
                        'confidence': confidence
                    })

        # ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        try:
            integrated_results = self.asr_post_processor.merge_short_segments(integrated_results)
        except Exception as e:
            print(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")

        return integrated_results

    def _save_results(self, results: List[Dict],
                      output_dir: Path,
                      audio_path: str) -> Dict[str, str]:
        """ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥"""

        output_files = {}
        base_name = Path(audio_path).stem

        try:
            # 1. CSV í˜•ì‹
            csv_path = output_dir / f"{base_name}_transcript.csv"
            if results:  # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì €ì¥
                df = pd.DataFrame(results)
                df.to_csv(csv_path, index=False, encoding='utf-8-sig')
                output_files['csv'] = str(csv_path)

            # 2. JSON í˜•ì‹
            json_path = output_dir / f"{base_name}_transcript.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            output_files['json'] = str(json_path)

            # 3. í…ìŠ¤íŠ¸ í˜•ì‹ (ì½ê¸° ì‰¬ìš´ ëŒ€í™”ë¡)
            txt_path = output_dir / f"{base_name}_conversation.txt"
            formatted_text = self._format_conversation_text(results)
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(formatted_text)
            output_files['txt'] = str(txt_path)

            # 4. SRT ìë§‰ í˜•ì‹
            if results:  # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ë§Œ SRT ìƒì„±
                srt_path = output_dir / f"{base_name}_subtitles.srt"
                srt_content = self._format_srt_subtitles(results)
                with open(srt_path, 'w', encoding='utf-8') as f:
                    f.write(srt_content)
                output_files['srt'] = str(srt_path)

        except Exception as e:
            print(f"âš ï¸ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            # ìµœì†Œí•œ JSONì€ ì €ì¥ ì‹œë„
            try:
                json_path = output_dir / f"{base_name}_transcript.json"
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                output_files['json'] = str(json_path)
            except:
                pass

        return output_files

    def _format_conversation_text(self, results: List[Dict]) -> str:
        """ëŒ€í™” í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""

        formatted_lines = []
        formatted_lines.append("=== ëŒ€í™” ì „ì‚¬ ê²°ê³¼ ===\n")

        if not results:
            formatted_lines.append("ì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.\n")
        else:
            for result in results:
                speaker = result.get('speaker_id', 'ì•Œ ìˆ˜ ì—†ìŒ')
                start_time = result.get('start_time', 0)
                text = result.get('text', '')
                confidence = result.get('confidence', 0)

                # ì‹œê°„ í¬ë§·íŒ… (MM:SS)
                minutes = int(start_time // 60)
                seconds = int(start_time % 60)
                time_str = f"{minutes:02d}:{seconds:02d}"

                # ì‹ ë¢°ë„ í‘œì‹œ
                confidence_icon = "ğŸŸ¢" if confidence > 0.9 else "ğŸŸ¡" if confidence > 0.7 else "ğŸ”´"

                formatted_lines.append(f"[{time_str}] {speaker}: {text} {confidence_icon}")

        # í†µê³„ ì •ë³´ ì¶”ê°€
        if results:
            unique_speakers = len(set(r.get('speaker_id', '') for r in results))
            total_duration = max((r.get('end_time', 0) for r in results), default=0)
        else:
            unique_speakers = 0
            total_duration = 0

        formatted_lines.append(f"\n=== í†µê³„ ===")
        formatted_lines.append(f"ì´ í™”ì ìˆ˜: {unique_speakers}ëª…")
        formatted_lines.append(f"ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")
        formatted_lines.append(f"ë°œí™” êµ¬ê°„: {len(results)}ê°œ")
        formatted_lines.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        return "\n".join(formatted_lines)

    def _format_srt_subtitles(self, results: List[Dict]) -> str:
        """SRT ìë§‰ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…"""

        if not results:
            return "1\n00:00:00,000 --> 00:00:01,000\nì¸ì‹ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.\n\n"

        srt_lines = []

        for i, result in enumerate(results, 1):
            start_time = result.get('start_time', 0)
            end_time = result.get('end_time', start_time + 1)
            speaker = result.get('speaker_id', 'ì•Œ ìˆ˜ ì—†ìŒ')
            text = result.get('text', '')

            # SRT ì‹œê°„ í˜•ì‹: HH:MM:SS,mmm
            start_srt = self._seconds_to_srt_time(start_time)
            end_srt = self._seconds_to_srt_time(end_time)

            srt_lines.append(str(i))
            srt_lines.append(f"{start_srt} --> {end_srt}")
            srt_lines.append(f"{speaker}: {text}")
            srt_lines.append("")  # ë¹ˆ ì¤„

        return "\n".join(srt_lines)

    def _seconds_to_srt_time(self, seconds: float) -> str:
        """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""

        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)

        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

    def _save_batch_summary(self, results: List[Dict], output_dir: Path):
        """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì €ì¥"""

        try:
            summary = {
                'processed_files': len(results),
                'successful': len([r for r in results if r.get('success', False)]),
                'failed': len([r for r in results if not r.get('success', False)]),
                'total_duration': sum(r.get('audio_duration', 0) for r in results if r.get('success', False)),
                'total_speakers': sum(r.get('num_speakers', 0) for r in results if r.get('success', False)),
                'processing_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'details': results
            }

            summary_path = output_dir / "batch_summary.json"
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)

            print(f"ğŸ“Š ë°°ì¹˜ ìš”ì•½ ì €ì¥: {summary_path}")
            print(f"ì„±ê³µ: {summary['successful']}/{summary['processed_files']}")

        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ìš”ì•½ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
            # ìµœì†Œí•œì˜ ìš”ì•½ì´ë¼ë„ ì¶œë ¥
            successful = len([r for r in results if r.get('success', False)])
            total = len(results)
            print(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {successful}/{total} ì„±ê³µ")


def create_cli_parser():
    """CLI ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""

    parser = argparse.ArgumentParser(
        description="í™”ì ë¶„ë¦¬ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
  python main.py single audio.wav

  # ë°°ì¹˜ ì²˜ë¦¬
  python main.py batch *.wav

  # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •
  python main.py single audio.wav --output ./results

  # ëª¨ë¸ ì§€ì •
  python main.py single audio.wav --model whisper-medium

  # ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
  python main.py info
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')

    # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
    single_parser = subparsers.add_parser('single', help='ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬')
    single_parser.add_argument('audio_file', help='ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼')
    single_parser.add_argument('--output', '-o', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    single_parser.add_argument('--speakers', '-s', type=int, help='ì˜ˆìƒ í™”ì ìˆ˜')
    single_parser.add_argument('--model', '-m', help='ì‚¬ìš©í•  Whisper ëª¨ë¸')
    single_parser.add_argument('--batch-size', type=int, help='ë°°ì¹˜ í¬ê¸°')

    # ë°°ì¹˜ ì²˜ë¦¬
    batch_parser = subparsers.add_parser('batch', help='ì—¬ëŸ¬ ì˜¤ë””ì˜¤ íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬')
    batch_parser.add_argument('audio_files', nargs='+', help='ì²˜ë¦¬í•  ì˜¤ë””ì˜¤ íŒŒì¼ë“¤')
    batch_parser.add_argument('--output', '-o', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    batch_parser.add_argument('--model', '-m', help='ì‚¬ìš©í•  Whisper ëª¨ë¸')
    batch_parser.add_argument('--batch-size', type=int, help='ë°°ì¹˜ í¬ê¸°')

    # ì‹œìŠ¤í…œ ì •ë³´
    info_parser = subparsers.add_parser('info', help='ì‹œìŠ¤í…œ ì •ë³´ ë° ê¶Œì¥ ì„¤ì • í™•ì¸')
    info_parser.add_argument('--benchmark', action='store_true', help='ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰')

    # ëŒ€í™”í˜• ëª¨ë“œ
    interactive_parser = subparsers.add_parser('interactive', help='ëŒ€í™”í˜• ëª¨ë“œ')

    return parser


def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    parser = create_cli_parser()
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 0

    # ì‹œìŠ¤í…œ ì •ë³´ ëª…ë ¹
    if args.command == 'info':
        print_system_info()

        if hasattr(args, 'benchmark') and args.benchmark:
            print("\nğŸ”¬ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰...")
            try:
                analyzer = PerformanceAnalyzer()

                # ëª¨ë¸ ë¡œë”© ë²¤ì¹˜ë§ˆí¬
                models = ['openai/whisper-base', 'openai/whisper-medium']
                benchmark_results = analyzer.benchmark_model_loading(models)

                print("\n=== ëª¨ë¸ ë¡œë”© ì„±ëŠ¥ ===")
                for model, result in benchmark_results.items():
                    if result['success']:
                        print(f"{model}:")
                        print(f"  ë¡œë”© ì‹œê°„: {result['load_time_seconds']:.2f}ì´ˆ")
                        print(f"  ë©”ëª¨ë¦¬ ì‚¬ìš©: {result['memory_usage_gb']:.2f}GB")
                    else:
                        print(f"{model}: âŒ ì‹¤íŒ¨ - {result['error']}")
            except Exception as e:
                print(f"âš ï¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

        return 0

    # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ì¤€ë¹„
    config_override = {}

    if hasattr(args, 'model') and args.model:
        # ëª¨ë¸ ì´ë¦„ ì •ê·œí™”
        model_name = args.model.lower()
        if not model_name.startswith('openai/whisper-'):
            model_name = f"openai/whisper-{model_name}"
        config_override['whisper_model'] = model_name

    if hasattr(args, 'batch_size') and args.batch_size:
        config_override['batch_size'] = args.batch_size

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    try:
        system = SpeakerDiarizationSystem(config_override)
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ì˜ì¡´ì„± íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return 1

    # ëª…ë ¹ë³„ ì²˜ë¦¬
    try:
        if args.command == 'single':
            # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
            if not os.path.exists(args.audio_file):
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.audio_file}")
                return 1

            result = system.process_audio_file(
                args.audio_file,
                getattr(args, 'output', None),
                getattr(args, 'speakers', None)
            )

            if result['success']:
                print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
                print(f"  ğŸ¯ ìŒì„± êµ¬ê°„: {result['num_segments']}ê°œ")
                print(f"  ğŸ‘¥ í™”ì ìˆ˜: {result['num_speakers']}ëª…")
                print(f"  â±ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´: {result['audio_duration']:.1f}ì´ˆ")
                print(f"  ğŸ“ ì¶œë ¥ íŒŒì¼:")
                for format_type, file_path in result['output_files'].items():
                    print(f"    {format_type.upper()}: {file_path}")
            else:
                print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                return 1

        elif args.command == 'batch':
            # ë°°ì¹˜ ì²˜ë¦¬
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            valid_files = []
            for file_path in args.audio_files:
                if os.path.exists(file_path):
                    valid_files.append(file_path)
                else:
                    print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")

            if not valid_files:
                print("âŒ ì²˜ë¦¬í•  ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return 1

            results = system.process_batch(valid_files, getattr(args, 'output', None))

            successful = len([r for r in results if r.get('success', False)])
            total = len(results)

            print(f"\nğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {successful}/{total} ì„±ê³µ")

            # ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ í‘œì‹œ
            failed_files = [r for r in results if not r.get('success', False)]
            if failed_files:
                print("âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:")
                for result in failed_files:
                    print(f"  {result['file_path']}: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

        elif args.command == 'interactive':
            # ëŒ€í™”í˜• ëª¨ë“œ
            interactive_mode(system)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        return 1
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()
        return 1

    return 0


def interactive_mode(system: SpeakerDiarizationSystem):
    """ëŒ€í™”í˜• ëª¨ë“œ"""

    print("\nğŸ¯ ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘")
    print("ëª…ë ¹ì–´:")
    print("  process <íŒŒì¼ê²½ë¡œ>  - íŒŒì¼ ì²˜ë¦¬")
    print("  info               - ì‹œìŠ¤í…œ ì •ë³´")
    print("  config             - í˜„ì¬ ì„¤ì • í™•ì¸")
    print("  help               - ë„ì›€ë§")
    print("  exit               - ì¢…ë£Œ")

    while True:
        try:
            command = input("\n> ").strip().split()

            if not command:
                continue

            cmd = command[0].lower()

            if cmd in ['exit', 'quit']:
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            elif cmd == 'help':
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
                print("  process <íŒŒì¼ê²½ë¡œ>  - ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬")
                print("  info               - ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥")
                print("  config             - í˜„ì¬ ì„¤ì • í™•ì¸")
                print("  help               - ì´ ë„ì›€ë§")
                print("  exit               - í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

            elif cmd == 'info':
                print_system_info()

            elif cmd == 'config':
                print("=== í˜„ì¬ ì„¤ì • ===")
                print(f"Whisper ëª¨ë¸: {model_config.whisper_model_name}")
                print(f"ë°°ì¹˜ í¬ê¸°: {processing_config.batch_size}")
                print(f"ì²­í¬ ê¸¸ì´: {processing_config.chunk_duration}ì´ˆ")
                print(f"ë””ë°”ì´ìŠ¤: {system_config.device}")
                print(f"FP16 ì‚¬ìš©: {processing_config.use_fp16}")

            elif cmd == 'process':
                if len(command) < 2:
                    print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ: process audio.wav")
                    continue

                file_path = command[1]

                if not os.path.exists(file_path):
                    print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                    continue

                print(f"ğŸš€ ì²˜ë¦¬ ì‹œì‘: {file_path}")

                try:
                    result = system.process_audio_file(file_path)

                    if result['success']:
                        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                        print(f"  í™”ì ìˆ˜: {result['num_speakers']}ëª…")
                        print(f"  êµ¬ê°„ ìˆ˜: {result['num_segments']}ê°œ")
                        print(f"  ê²°ê³¼ íŒŒì¼: {result['output_files'].get('txt', 'N/A')}")
                    else:
                        print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")

                except Exception as e:
                    print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            else:
                print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {cmd}")
                print("helpë¥¼ ì…ë ¥í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def check_dependencies():
    """í•„ìˆ˜ ì˜ì¡´ì„± í™•ì¸"""

    required_packages = [
        'torch', 'transformers', 'librosa', 'soundfile',
        'pandas', 'numpy', 'sklearn'
    ]

    missing_packages = []

    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)

    if missing_packages:
        print("âŒ ë‹¤ìŒ íŒ¨í‚¤ì§€ë“¤ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:")
        for pkg in missing_packages:
            print(f"  - {pkg}")
        print("\nì„¤ì¹˜ ëª…ë ¹ì–´:")
        print(f"pip install {' '.join(missing_packages)}")
        return False

    return True


def setup_logging():
    """ë¡œê¹… ì„¤ì •"""

    import logging

    logging.basicConfig(
        level=getattr(logging, system_config.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('speaker_diarization.log'),
            logging.StreamHandler()
        ]
    )


def show_welcome_message():
    """í™˜ì˜ ë©”ì‹œì§€ ì¶œë ¥"""

    print("=" * 60)
    print("ğŸ¤ í™”ì ë¶„ë¦¬ ìŒì„± ì¸ì‹ ì‹œìŠ¤í…œ")
    print("RTX 4060 ìµœì í™” í•œêµ­ì–´ AI ìŒì„± ë¶„ì„")
    print("=" * 60)
    print()


if __name__ == "__main__":
    # í™˜ì˜ ë©”ì‹œì§€
    show_welcome_message()

    # ì˜ì¡´ì„± í™•ì¸
    if not check_dependencies():
        sys.exit(1)

    # ë¡œê¹… ì„¤ì •
    setup_logging()

    # ë©”ì¸ ì‹¤í–‰
    sys.exit(main())
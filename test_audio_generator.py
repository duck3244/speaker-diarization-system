# test_audio_generator.py
"""
í…ŒìŠ¤íŠ¸ìš© ìŒì„± íŒŒì¼ ìƒì„±ê¸°
"""

import numpy as np
import soundfile as sf
from pathlib import Path
import random


def generate_test_conversation(
        output_path: str = "test_conversation.wav",
        duration: float = 30.0,
        num_speakers: int = 2,
        sample_rate: int = 16000
):
    """
    í…ŒìŠ¤íŠ¸ìš© ëŒ€í™” ìŒì„± ìƒì„± (ìŒì„± í•©ì„± ì—†ì´ íŒ¨í„´ ê¸°ë°˜)
    ì‹¤ì œë¡œëŠ” TTSë‚˜ ë…¹ìŒì´ í•„ìš”í•˜ì§€ë§Œ, êµ¬ì¡°ì  í…ŒìŠ¤íŠ¸ìš©
    """

    # ì „ì²´ ìƒ˜í”Œ ìˆ˜
    total_samples = int(duration * sample_rate)
    audio = np.zeros(total_samples)

    # í™”ìë³„ íŠ¹ì„± (ì£¼íŒŒìˆ˜, ì§„í­ íŒ¨í„´)
    speaker_configs = [
        {"freq": 150 + i * 50, "amplitude": 0.3 + i * 0.1}
        for i in range(num_speakers)
    ]

    # ë°œí™” êµ¬ê°„ ìƒì„±
    segments = []
    current_time = 1.0  # 1ì´ˆë¶€í„° ì‹œì‘

    while current_time < duration - 2:
        speaker_id = random.randint(0, num_speakers - 1)
        segment_duration = random.uniform(2.0, 5.0)  # 2-5ì´ˆ ë°œí™”

        if current_time + segment_duration > duration - 1:
            segment_duration = duration - current_time - 1

        segments.append({
            'speaker': speaker_id,
            'start': current_time,
            'end': current_time + segment_duration,
            'duration': segment_duration
        })

        current_time += segment_duration + random.uniform(0.5, 1.5)  # ê°„ê²©

    # ìŒì„± ì‹ í˜¸ ìƒì„±
    for segment in segments:
        start_sample = int(segment['start'] * sample_rate)
        end_sample = int(segment['end'] * sample_rate)

        config = speaker_configs[segment['speaker']]

        # ê¸°ë³¸ í†¤ ìƒì„±
        t = np.linspace(0, segment['duration'], end_sample - start_sample)

        # ë³µí•© ì£¼íŒŒìˆ˜ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± íŒ¨í„´)
        signal = (
                config['amplitude'] * np.sin(2 * np.pi * config['freq'] * t) +
                config['amplitude'] * 0.3 * np.sin(2 * np.pi * config['freq'] * 2 * t) +
                config['amplitude'] * 0.1 * np.sin(2 * np.pi * config['freq'] * 3 * t)
        )

        # ì—”ë²¨ë¡œí”„ ì ìš© (ìì—°ìŠ¤ëŸ¬ìš´ í˜ì´ë“œ)
        envelope = np.ones_like(signal)
        fade_samples = int(0.1 * sample_rate)  # 0.1ì´ˆ í˜ì´ë“œ

        if len(signal) > 2 * fade_samples:
            envelope[:fade_samples] = np.linspace(0, 1, fade_samples)
            envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)

        signal *= envelope

        # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ (í˜„ì‹¤ì ì¸ ìŒì„±)
        noise = np.random.normal(0, 0.02, len(signal))
        signal += noise

        # ì˜¤ë””ì˜¤ì— ì¶”ê°€
        audio[start_sample:end_sample] = signal

    # ì •ê·œí™”
    audio = audio / np.max(np.abs(audio)) * 0.8

    # ì €ì¥
    sf.write(output_path, audio, sample_rate)

    # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì €ì¥
    info_path = output_path.replace('.wav', '_info.txt')
    with open(info_path, 'w', encoding='utf-8') as f:
        f.write(f"í…ŒìŠ¤íŠ¸ ëŒ€í™” - {num_speakers}ëª… í™”ì\n")
        f.write(f"ì´ ê¸¸ì´: {duration:.1f}ì´ˆ\n\n")
        f.write("ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´:\n")
        for i, seg in enumerate(segments):
            f.write(f"{i + 1}. í™”ì_{seg['speaker']} ({seg['start']:.1f}s - {seg['end']:.1f}s)\n")

    print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±: {output_path}")
    print(f"ğŸ“„ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´: {info_path}")

    return segments


def download_sample_audio():
    """
    ìƒ˜í”Œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ ì¶œë ¥
    """

    samples = [
        {
            "name": "ì§§ì€ ëŒ€í™” (2ëª…)",
            "description": "2ëª…ì´ ê°„ë‹¨í•œ ëŒ€í™”",
            "duration": "1-3ë¶„",
            "difficulty": "ì‰¬ì›€",
            "example": "ì¹œêµ¬ë¼ë¦¬ ì•ˆë¶€ ì¸ì‚¬"
        },
        {
            "name": "ë‰´ìŠ¤ ì¸í„°ë·° (2-3ëª…)",
            "description": "ì•µì»¤ + ê²ŒìŠ¤íŠ¸ ì¸í„°ë·°",
            "duration": "5-10ë¶„",
            "difficulty": "ë³´í†µ",
            "example": "KBS, MBC ë‰´ìŠ¤ ì¸í„°ë·°"
        },
        {
            "name": "í† ë¡  í”„ë¡œê·¸ë¨ (3-4ëª…)",
            "description": "ì—¬ëŸ¬ ëª…ì´ ì°¸ì—¬í•˜ëŠ” í† ë¡ ",
            "duration": "10-30ë¶„",
            "difficulty": "ì–´ë ¤ì›€",
            "example": "100ë¶„ í† ë¡ , ì‹¬ì•¼í† ë¡ "
        },
        {
            "name": "íŒŸìºìŠ¤íŠ¸ (2-3ëª…)",
            "description": "ì§„í–‰ì + ê²ŒìŠ¤íŠ¸ ëŒ€í™”",
            "duration": "20-60ë¶„",
            "difficulty": "ë³´í†µ",
            "example": "ê¹€ì–´ì¤€ì˜ ë‰´ìŠ¤ê³µì¥"
        }
    ]

    print("=== ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ===\n")

    for i, sample in enumerate(samples, 1):
        print(f"{i}. {sample['name']}")
        print(f"   ì„¤ëª…: {sample['description']}")
        print(f"   ê¸¸ì´: {sample['duration']}")
        print(f"   ë‚œì´ë„: {sample['difficulty']}")
        print(f"   ì˜ˆì‹œ: {sample['example']}")
        print()


def create_test_suite():
    """í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±"""

    output_dir = Path("test_audio")
    output_dir.mkdir(exist_ok=True)

    test_cases = [
        {"name": "short_2speakers", "duration": 15, "speakers": 2},
        {"name": "medium_3speakers", "duration": 60, "speakers": 3},
        {"name": "long_2speakers", "duration": 180, "speakers": 2},
        {"name": "complex_4speakers", "duration": 120, "speakers": 4},
    ]

    print("ğŸµ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„± ì¤‘...\n")

    for case in test_cases:
        output_path = output_dir / f"{case['name']}.wav"
        print(f"ìƒì„± ì¤‘: {case['name']}")

        segments = generate_test_conversation(
            output_path=str(output_path),
            duration=case['duration'],
            num_speakers=case['speakers']
        )

        print(f"  - {case['speakers']}ëª… í™”ì")
        print(f"  - {case['duration']}ì´ˆ ê¸¸ì´")
        print(f"  - {len(segments)}ê°œ ë°œí™” êµ¬ê°„\n")

    print("âœ… í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_dir.absolute()}")


def generate_test_conversation(
        output_path: str = "test_conversation.wav",
        duration: float = 30.0,
        num_speakers: int = 2,
        sample_rate: int = 16000
):
    """
    í…ŒìŠ¤íŠ¸ìš© ëŒ€í™” ìŒì„± ìƒì„± (ìŒì„± í•©ì„± ì—†ì´ íŒ¨í„´ ê¸°ë°˜)
    ì‹¤ì œë¡œëŠ” TTSë‚˜ ë…¹ìŒì´ í•„ìš”í•˜ì§€ë§Œ, êµ¬ì¡°ì  í…ŒìŠ¤íŠ¸ìš©
    """

    # ì „ì²´ ìƒ˜í”Œ ìˆ˜
    total_samples = int(duration * sample_rate)
    audio = np.zeros(total_samples)

    # í™”ìë³„ íŠ¹ì„± (ì£¼íŒŒìˆ˜, ì§„í­ íŒ¨í„´)
    speaker_configs = [
        {"freq": 150 + i * 50, "amplitude": 0.3 + i * 0.1}
        for i in range(num_speakers)
    ]

    # ë°œí™” êµ¬ê°„ ìƒì„±
    segments = []
    current_time = 1.0  # 1ì´ˆë¶€í„° ì‹œì‘

    while current_time < duration - 2:
        speaker_id = random.randint(0, num_speakers - 1)
        segment_duration = random.uniform(2.0, 5.0)  # 2-5ì´ˆ ë°œí™”

        if current_time + segment_duration > duration - 1:
            segment_duration = duration - current_time - 1

        segments.append({
            'speaker': speaker_id,
            'start': current_time,
            'end': current_time + segment_duration,
            'duration': segment_duration
        })

        current_time += segment_duration + random.uniform(0.5, 1.5)  # ê°„ê²©

    # ìŒì„± ì‹ í˜¸ ìƒì„±
    for segment in segments:
        start_sample = int(segment['start'] * sample_rate)
        end_sample = int(segment['end'] * sample_rate)

        config = speaker_configs[segment['speaker']]

        # ê¸°ë³¸ í†¤ ìƒì„±
        t = np.linspace(0, segment['duration'], end_sample - start_sample)

        # ë³µí•© ì£¼íŒŒìˆ˜ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± íŒ¨í„´)
        signal = (
                config['amplitude'] * np.sin(2 * np.pi * config['freq'] * t) +
                config['amplitude'] * 0.3 * np.sin(2 * np.pi * config['freq'] * 2 * t) +
                config['amplitude'] * 0.1 * np.sin(2 * np.pi * config['freq'] * 3 * t)
        )

        # ì—”ë²¨ë¡œí”„ ì ìš© (ìì—°ìŠ¤ëŸ¬ìš´ í˜ì´ë“œ)
        envelope = np.ones_like(signal)
        fade_samples = int(0.1 * sample_rate)  # 0.1ì´ˆ í˜ì´ë“œ

        if len(signal) > 2 * fade_samples:
            envelope[:fade_samples] = np.linspace(0, 1, fade_samples)
            envelope[-fade_samples:] = np.linspace(1, 0, fade_samples)

        signal *= envelope

        # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ (í˜„ì‹¤ì ì¸ ìŒì„±)
        noise = np.random.normal(0, 0.02, len(signal))
        signal += noise

        # ì˜¤ë””ì˜¤ì— ì¶”ê°€
        audio[start_sample:end_sample] = signal

    # ì •ê·œí™”
    audio = audio / np.max(np.abs(audio)) * 0.8

    # ì €ì¥
    sf.write(output_path, audio, sample_rate)

    # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì €ì¥
    info_path = output_path.replace('.wav', '_info.txt')
    with open(info_path, 'w', encoding='utf-8') as f:
        f.write(f"í…ŒìŠ¤íŠ¸ ëŒ€í™” - {num_speakers}ëª… í™”ì\n")
        f.write(f"ì´ ê¸¸ì´: {duration:.1f}ì´ˆ\n\n")
        f.write("ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´:\n")
        for i, seg in enumerate(segments):
            f.write(f"{i + 1}. í™”ì_{seg['speaker']} ({seg['start']:.1f}s - {seg['end']:.1f}s)\n")

    print(f"âœ… í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±: {output_path}")
    print(f"ğŸ“„ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´: {info_path}")

    return segments


def generate_realistic_test_conversation(
        output_path: str = "realistic_test.wav",
        duration: float = 30.0,
        num_speakers: int = 2,
        sample_rate: int = 16000
):
    """
    ë” í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ìš© ëŒ€í™” ìŒì„± ìƒì„±
    """

    # ì „ì²´ ìƒ˜í”Œ ìˆ˜
    total_samples = int(duration * sample_rate)
    audio = np.zeros(total_samples)

    # í™”ìë³„ íŠ¹ì„± (ë” êµ¬ë¶„ë˜ëŠ” íŠ¹ì„±)
    speaker_configs = [
        {"base_freq": 120, "formant1": 800, "formant2": 1200, "amplitude": 0.4},  # ë‚¨ì„± ëª©ì†Œë¦¬
        {"base_freq": 180, "formant1": 1000, "formant2": 1800, "amplitude": 0.35},  # ì—¬ì„± ëª©ì†Œë¦¬
        {"base_freq": 150, "formant1": 900, "formant2": 1500, "amplitude": 0.38},  # ì¤‘ê°„ ëª©ì†Œë¦¬
        {"base_freq": 100, "formant1": 750, "formant2": 1100, "amplitude": 0.42}  # ë‚®ì€ ëª©ì†Œë¦¬
    ]

    # ë” í˜„ì‹¤ì ì¸ ë°œí™” íŒ¨í„´
    segments = []
    current_time = 1.0

    # ëŒ€í™” íŒ¨í„´: ë²ˆê°ˆì•„ê°€ë©° ë§í•˜ê¸°
    current_speaker = 0

    while current_time < duration - 2:
        # ë°œí™” ê¸¸ì´ë¥¼ ë” ë‹¤ì–‘í•˜ê²Œ
        if random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ì§§ì€ ë°œí™”
            segment_duration = random.uniform(1.0, 2.5)
        else:  # 70% í™•ë¥ ë¡œ ê¸´ ë°œí™”
            segment_duration = random.uniform(3.0, 8.0)

        if current_time + segment_duration > duration - 1:
            segment_duration = duration - current_time - 1

        segments.append({
            'speaker': current_speaker,
            'start': current_time,
            'end': current_time + segment_duration,
            'duration': segment_duration
        })

        # ë‹¤ìŒ í™”ìë¡œ ì „í™˜ (ê°€ë” ë™ì¼ í™”ì ì—°ì†)
        if random.random() < 0.8:  # 80% í™•ë¥ ë¡œ í™”ì ë³€ê²½
            current_speaker = (current_speaker + 1) % num_speakers

        # ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ê°„ê²©
        current_time += segment_duration + random.uniform(0.2, 1.0)

    # ë” ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ì‹ í˜¸ ìƒì„±
    for segment in segments:
        start_sample = int(segment['start'] * sample_rate)
        end_sample = int(segment['end'] * sample_rate)

        config = speaker_configs[segment['speaker'] % len(speaker_configs)]

        # ì‹œê°„ ë²¡í„°
        t = np.linspace(0, segment['duration'], end_sample - start_sample)

        # ê¸°ë³¸ ì£¼íŒŒìˆ˜ ë³€í™” (ì–µì–‘)
        pitch_variation = 1 + 0.1 * np.sin(2 * np.pi * 0.5 * t)  # ì²œì²œíˆ ë³€í•˜ëŠ” ì–µì–‘
        base_freq = config['base_freq'] * pitch_variation

        # í¬ë¨¼íŠ¸ê°€ í¬í•¨ëœ ë³µí•© ì‹ í˜¸
        signal = (
            # ê¸°ë³¸ ì£¼íŒŒìˆ˜
                config['amplitude'] * np.sin(2 * np.pi * base_freq * t) * 0.6 +
                # ì²« ë²ˆì§¸ í¬ë¨¼íŠ¸
                config['amplitude'] * 0.3 * np.sin(2 * np.pi * config['formant1'] * t) +
                # ë‘ ë²ˆì§¸ í¬ë¨¼íŠ¸
                config['amplitude'] * 0.2 * np.sin(2 * np.pi * config['formant2'] * t) +
                # í•˜ëª¨ë‹‰ìŠ¤
                config['amplitude'] * 0.1 * np.sin(2 * np.pi * base_freq * 2 * t) +
                config['amplitude'] * 0.05 * np.sin(2 * np.pi * base_freq * 3 * t)
        )

        # AM ë³€ì¡° (ìŒì„±ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë³€í™”)
        am_freq = random.uniform(5, 15)  # 5-15Hz ë³€ì¡°
        am_mod = 0.8 + 0.2 * np.sin(2 * np.pi * am_freq * t)
        signal *= am_mod

        # ìì—°ìŠ¤ëŸ¬ìš´ ì—”ë²¨ë¡œí”„
        envelope = np.ones_like(signal)
        fade_samples = int(0.05 * sample_rate)  # 50ms í˜ì´ë“œ

        if len(signal) > 2 * fade_samples:
            # ë¶€ë“œëŸ¬ìš´ í˜ì´ë“œ ì¸/ì•„ì›ƒ
            envelope[:fade_samples] = 0.5 * (1 - np.cos(np.pi * np.arange(fade_samples) / fade_samples))
            envelope[-fade_samples:] = 0.5 * (1 + np.cos(np.pi * np.arange(fade_samples) / fade_samples))

        signal *= envelope

        # ë°°ê²½ ë…¸ì´ì¦ˆ ì¶”ê°€ (ë” í˜„ì‹¤ì )
        noise_level = 0.015
        noise = np.random.normal(0, noise_level, len(signal))
        signal += noise

        # ê°„í—ì ì¸ ë¸Œë ˆìŠ¤ ì‚¬ìš´ë“œ (ìˆ¨ì†Œë¦¬)
        if random.random() < 0.3 and len(signal) > sample_rate:
            breath_pos = random.randint(sample_rate // 4, len(signal) - sample_rate // 4)
            breath_length = int(0.1 * sample_rate)  # 100ms ë¸Œë ˆìŠ¤
            breath_sound = np.random.normal(0, 0.02, breath_length) * np.exp(
                -np.arange(breath_length) / (0.05 * sample_rate))
            signal[breath_pos:breath_pos + breath_length] += breath_sound[:min(breath_length, len(signal) - breath_pos)]

        # ì˜¤ë””ì˜¤ì— ì¶”ê°€
        audio[start_sample:end_sample] = signal

    # ì „ì²´ì ì¸ ë°°ê²½ ë…¸ì´ì¦ˆ (ë§¤ìš° ì•½í•˜ê²Œ)
    background_noise = np.random.normal(0, 0.005, len(audio))
    audio += background_noise

    # ì •ê·œí™” (í”¼í¬ê°€ 0.9ë¥¼ ë„˜ì§€ ì•Šë„ë¡)
    max_val = np.max(np.abs(audio))
    if max_val > 0:
        audio = audio / max_val * 0.9

    # ì €ì¥
    sf.write(output_path, audio, sample_rate)

    # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì €ì¥
    info_path = output_path.replace('.wav', '_segments.txt')
    with open(info_path, 'w', encoding='utf-8') as f:
        f.write(f"í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ ëŒ€í™” - {num_speakers}ëª… í™”ì\n")
        f.write(f"ì´ ê¸¸ì´: {duration:.1f}ì´ˆ\n")
        f.write(f"ì´ ì„¸ê·¸ë¨¼íŠ¸: {len(segments)}ê°œ\n\n")
        f.write("ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´:\n")
        for i, seg in enumerate(segments):
            f.write(
                f"{i + 1:2d}. í™”ì_{seg['speaker']} ({seg['start']:5.1f}s - {seg['end']:5.1f}s, {seg['duration']:4.1f}s)\n")

        # í™”ìë³„ í†µê³„
        f.write(f"\ní™”ìë³„ ë°œí™” ì‹œê°„:\n")
        for speaker_id in range(num_speakers):
            speaker_segments = [s for s in segments if s['speaker'] == speaker_id]
            total_time = sum(s['duration'] for s in speaker_segments)
            f.write(f"í™”ì_{speaker_id}: {total_time:5.1f}ì´ˆ ({len(speaker_segments)}ê°œ êµ¬ê°„)\n")

    print(f"âœ… í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±: {output_path}")
    print(f"ğŸ“„ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´: {info_path}")
    print(f"ğŸ“Š {len(segments)}ê°œ ë°œí™” êµ¬ê°„, {num_speakers}ëª… í™”ì")

    return segments
    """
    ìƒ˜í”Œ ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ ì¶œë ¥
    """

    samples = [
        {
            "name": "ì§§ì€ ëŒ€í™” (2ëª…)",
            "description": "2ëª…ì´ ê°„ë‹¨í•œ ëŒ€í™”",
            "duration": "1-3ë¶„",
            "difficulty": "ì‰¬ì›€",
            "example": "ì¹œêµ¬ë¼ë¦¬ ì•ˆë¶€ ì¸ì‚¬"
        },
        {
            "name": "ë‰´ìŠ¤ ì¸í„°ë·° (2-3ëª…)",
            "description": "ì•µì»¤ + ê²ŒìŠ¤íŠ¸ ì¸í„°ë·°",
            "duration": "5-10ë¶„",
            "difficulty": "ë³´í†µ",
            "example": "KBS, MBC ë‰´ìŠ¤ ì¸í„°ë·°"
        },
        {
            "name": "í† ë¡  í”„ë¡œê·¸ë¨ (3-4ëª…)",
            "description": "ì—¬ëŸ¬ ëª…ì´ ì°¸ì—¬í•˜ëŠ” í† ë¡ ",
            "duration": "10-30ë¶„",
            "difficulty": "ì–´ë ¤ì›€",
            "example": "100ë¶„ í† ë¡ , ì‹¬ì•¼í† ë¡ "
        },
        {
            "name": "íŒŸìºìŠ¤íŠ¸ (2-3ëª…)",
            "description": "ì§„í–‰ì + ê²ŒìŠ¤íŠ¸ ëŒ€í™”",
            "duration": "20-60ë¶„",
            "difficulty": "ë³´í†µ",
            "example": "ê¹€ì–´ì¤€ì˜ ë‰´ìŠ¤ê³µì¥"
        }
    ]

    print("=== ì¶”ì²œ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ===\n")

    for i, sample in enumerate(samples, 1):
        print(f"{i}. {sample['name']}")
        print(f"   ì„¤ëª…: {sample['description']}")
        print(f"   ê¸¸ì´: {sample['duration']}")
        print(f"   ë‚œì´ë„: {sample['difficulty']}")
        print(f"   ì˜ˆì‹œ: {sample['example']}")
        print()


def create_test_suite():
    """í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±"""

    output_dir = Path("test_audio")
    output_dir.mkdir(exist_ok=True)

    test_cases = [
        {"name": "short_2speakers", "duration": 15, "speakers": 2},
        {"name": "medium_3speakers", "duration": 60, "speakers": 3},
        {"name": "long_2speakers", "duration": 180, "speakers": 2},
        {"name": "complex_4speakers", "duration": 120, "speakers": 4},
    ]

    print("ğŸµ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„± ì¤‘...\n")

    for case in test_cases:
        output_path = output_dir / f"{case['name']}.wav"
        print(f"ìƒì„± ì¤‘: {case['name']}")

        segments = generate_test_conversation(
            output_path=str(output_path),
            duration=case['duration'],
            num_speakers=case['speakers']
        )

        print(f"  - {case['speakers']}ëª… í™”ì")
        print(f"  - {case['duration']}ì´ˆ ê¸¸ì´")
        print(f"  - {len(segments)}ê°œ ë°œí™” êµ¬ê°„\n")

    print("âœ… í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_dir.absolute()}")


if __name__ == "__main__":
    print("ğŸ¤ í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ìƒì„±ê¸°")
    print("=" * 50)

    # ìƒ˜í”Œ ì¶”ì²œ
    download_sample_audio()

    # ë” í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
    print("\ní˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±...")

    # ê°„ë‹¨í•œ 2ëª… ëŒ€í™” (30ì´ˆ)
    generate_realistic_test_conversation(
        output_path="realistic_2speakers_30s.wav",
        duration=30,
        num_speakers=2
    )

    # ë³µì¡í•œ 3ëª… ëŒ€í™” (60ì´ˆ)
    generate_realistic_test_conversation(
        output_path="realistic_3speakers_60s.wav",
        duration=60,
        num_speakers=3
    )

    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print("\ní…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´:")
    print("python main.py single realistic_2speakers_30s.wav")
    print("python main.py single realistic_3speakers_60s.wav")